{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782},{"sourceId":7402356,"sourceType":"datasetVersion","datasetId":4304475},{"sourceId":7403069,"sourceType":"datasetVersion","datasetId":4304949},{"sourceId":7447509,"sourceType":"datasetVersion","datasetId":4334995},{"sourceId":7450712,"sourceType":"datasetVersion","datasetId":4336944},{"sourceId":7465251,"sourceType":"datasetVersion","datasetId":4317718},{"sourceId":7792050,"sourceType":"datasetVersion","datasetId":4561256},{"sourceId":7792068,"sourceType":"datasetVersion","datasetId":4561271},{"sourceId":8046630,"sourceType":"datasetVersion","datasetId":4406611,"isSourceIdPinned":true},{"sourceId":8048221,"sourceType":"datasetVersion","datasetId":4723894},{"sourceId":8048710,"sourceType":"datasetVersion","datasetId":4746291},{"sourceId":8057669,"sourceType":"datasetVersion","datasetId":4752617},{"sourceId":8057843,"sourceType":"datasetVersion","datasetId":4752731},{"sourceId":8057847,"sourceType":"datasetVersion","datasetId":4752734},{"sourceId":8057855,"sourceType":"datasetVersion","datasetId":4752740},{"sourceId":8057997,"sourceType":"datasetVersion","datasetId":4752850},{"sourceId":158958765,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":270.012179,"end_time":"2024-01-14T22:56:02.916427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-14T22:51:32.904248","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ensemble and Inference \n\nWeighted ensemble and inference of efficient net , wave net and cat boost models using weights as \n0.80, 0.15 and 0.05 respectively ","metadata":{"papermill":{"duration":14.80928,"end_time":"2024-01-14T22:51:51.64702","exception":false,"start_time":"2024-01-14T22:51:36.83774","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:07:24.622184Z","iopub.execute_input":"2024-04-07T23:07:24.622875Z","iopub.status.idle":"2024-04-07T23:07:44.064067Z","shell.execute_reply.started":"2024-04-07T23:07:24.622846Z","shell.execute_reply":"2024-04-07T23:07:44.06311Z"}}},{"cell_type":"code","source":"import os, gc\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\nimport tensorflow as tf\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nprint('TensorFlow version =',tf.__version__)\n\n# USE MULTIPLE GPUS\ngpus = tf.config.list_physical_devices('GPU')\nif len(gpus)<=1: \n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    print(f'Using {len(gpus)} GPU')\nelse: \n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} GPUs')\n\nVER = 3\n\nLOAD_MODELS_FROMb0 = '/kaggle/input/abcdefghi/'\nLOAD_MODELS_FROMb1='/kaggle/input/version-10-b1-two-step-hms/'\nLOAD_MODELS_FROMb2=\"/kaggle/input/version-10-b2-two-step-hms/\"\nLOAD_MODELS_FROMb3=\"/kaggle/input/version-10-b3-two-step-hms/\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MIXED PRECISION\nMIX = True\nif MIX:\n    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n    print('Mixed precision enabled')\nelse:\n    print('Using full precision')","metadata":{"papermill":{"duration":0.016556,"end_time":"2024-01-14T22:51:51.671783","exception":false,"start_time":"2024-01-14T22:51:51.655227","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:07:44.065951Z","iopub.execute_input":"2024-04-07T23:07:44.066536Z","iopub.status.idle":"2024-04-07T23:07:44.073786Z","shell.execute_reply.started":"2024-04-07T23:07:44.066506Z","shell.execute_reply":"2024-04-07T23:07:44.072665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = df.columns[-6:]","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.288611,"end_time":"2024-01-14T22:51:51.984993","exception":false,"start_time":"2024-01-14T22:51:51.696382","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:07:44.07512Z","iopub.execute_input":"2024-04-07T23:07:44.075635Z","iopub.status.idle":"2024-04-07T23:07:44.358001Z","shell.execute_reply.started":"2024-04-07T23:07:44.075596Z","shell.execute_reply":"2024-04-07T23:07:44.357221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Efficient Net models","metadata":{}},{"cell_type":"code","source":"import albumentations as albu\nTARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\nTARS2 = {x:y for y,x in TARS.items()}\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, data, batch_size=32, shuffle=False, augment=False, mode='train',\n                 specs = None, eeg_specs = None): \n\n        self.data = data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.mode = mode\n        self.specs = specs\n        self.eeg_specs = eeg_specs\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        if self.augment: X = self.__augment_batch(X) \n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange( len(self.data) )\n        if self.shuffle: np.random.shuffle(self.indexes)\n                        \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        \n        X = np.zeros((len(indexes),128,256,8),dtype='float32')\n        y = np.zeros((len(indexes),6),dtype='float32')\n        img = np.ones((128,256),dtype='float32')\n        \n        for j,i in enumerate(indexes):\n            row = self.data.iloc[i]\n            if self.mode=='test': \n                r = 0\n            else: \n                r = int( (row['min'] + row['max'])//4 )\n\n            for k in range(4):\n                # EXTRACT 300 ROWS OF SPECTROGRAM\n                img = self.specs[row.spec_id][r:r+300,k*100:(k+1)*100].T\n                \n                # LOG TRANSFORM SPECTROGRAM\n                img = np.clip(img,0,32)\n                img = np.nan_to_num(img, nan=0.0)\n                img = img / 32\n                \n                # CROP TO 256 TIME STEPS\n                X[j,14:-14,:,k] = img[:,22:-22]\n        \n            # EEG SPECTROGRAMS\n            img = self.eeg_specs[row.eeg_id]\n            X[j,:,:,4:] = img\n                \n            if self.mode!='test':\n                y[j,] = row[TARGETS]\n            \n        return X,y\n    \n    def __random_transform(self, img):\n        composition = albu.Compose([\n            albu.HorizontalFlip(p=0.5),\n        ])\n        return composition(image=img)['image']\n            \n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n        return img_batch","metadata":{"papermill":{"duration":2.369789,"end_time":"2024-01-14T22:52:49.721728","exception":false,"start_time":"2024-01-14T22:52:47.351939","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:07:44.391315Z","iopub.execute_input":"2024-04-07T23:07:44.391725Z","iopub.status.idle":"2024-04-07T23:07:46.950634Z","shell.execute_reply.started":"2024-04-07T23:07:44.391699Z","shell.execute_reply":"2024-04-07T23:07:46.949861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl","metadata":{"_kg_hide-output":true,"papermill":{"duration":13.587235,"end_time":"2024-01-14T22:53:06.589596","exception":false,"start_time":"2024-01-14T22:52:53.002361","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:07:46.987462Z","iopub.execute_input":"2024-04-07T23:07:46.987778Z","iopub.status.idle":"2024-04-07T23:08:01.017484Z","shell.execute_reply.started":"2024-04-07T23:07:46.987754Z","shell.execute_reply":"2024-04-07T23:08:01.016254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\n\ndef build_modelb0():\n    \n    inp = tf.keras.Input(shape=(128,256,8))\n    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    \n    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n    # KAGGLE SPECTROGRAMS\n    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n    #x1=x1-[0.45]\n    # EEG SPECTROGRAMS\n    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n    # MAKE 512X512X3\n    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    elif USE_EEG_SPECTROGRAMS: x = x2\n    else: x = x1\n    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n    \n    # OUTPUT\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n\n    model.compile(loss=loss, optimizer = opt) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:01.0191Z","iopub.execute_input":"2024-04-07T23:08:01.019463Z","iopub.status.idle":"2024-04-07T23:08:01.043265Z","shell.execute_reply.started":"2024-04-07T23:08:01.019402Z","shell.execute_reply":"2024-04-07T23:08:01.042399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_modelb1():\n    \n    inp = tf.keras.Input(shape=(128,256,8))\n    base_model = efn.EfficientNetB1(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    \n    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n    # KAGGLE SPECTROGRAMS\n    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n    #x1=x1-[0.45]\n    # EEG SPECTROGRAMS\n    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n    # MAKE 512X512X3\n    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    elif USE_EEG_SPECTROGRAMS: x = x2\n    else: x = x1\n    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n    \n    # OUTPUT\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n\n    model.compile(loss=loss, optimizer = opt) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:01.044377Z","iopub.execute_input":"2024-04-07T23:08:01.044737Z","iopub.status.idle":"2024-04-07T23:08:01.055229Z","shell.execute_reply.started":"2024-04-07T23:08:01.044711Z","shell.execute_reply":"2024-04-07T23:08:01.054313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_modelb2():\n    \n    inp = tf.keras.Input(shape=(128,256,8))\n    base_model = efn.EfficientNetB2(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    \n    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n    # KAGGLE SPECTROGRAMS\n    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n    #x1=x1-[0.45]\n    # EEG SPECTROGRAMS\n    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n    # MAKE 512X512X3\n    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    elif USE_EEG_SPECTROGRAMS: x = x2\n    else: x = x1\n    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n    \n    # OUTPUT\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n\n    model.compile(loss=loss, optimizer = opt) \n        \n    return model","metadata":{"papermill":{"duration":0.057714,"end_time":"2024-01-14T22:53:06.682056","exception":false,"start_time":"2024-01-14T22:53:06.624342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:08:01.056335Z","iopub.execute_input":"2024-04-07T23:08:01.05667Z","iopub.status.idle":"2024-04-07T23:08:01.074369Z","shell.execute_reply.started":"2024-04-07T23:08:01.056645Z","shell.execute_reply":"2024-04-07T23:08:01.073465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_modelb3():\n    \n    inp = tf.keras.Input(shape=(128,256,8))\n    base_model = efn.EfficientNetB3(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    \n    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n    # KAGGLE SPECTROGRAMS\n    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n    #x1=x1-[0.45]\n    # EEG SPECTROGRAMS\n    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n    # MAKE 512X512X3\n    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    elif USE_EEG_SPECTROGRAMS: x = x2\n    else: x = x1\n    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n    \n    # OUTPUT\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n\n    model.compile(loss=loss, optimizer = opt) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:01.075865Z","iopub.execute_input":"2024-04-07T23:08:01.076134Z","iopub.status.idle":"2024-04-07T23:08:01.09115Z","shell.execute_reply.started":"2024-04-07T23:08:01.076101Z","shell.execute_reply":"2024-04-07T23:08:01.090219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test ","metadata":{"papermill":{"duration":0.050491,"end_time":"2024-01-14T22:55:48.321932","exception":false,"start_time":"2024-01-14T22:55:48.271441","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape',test.shape)\ntest.head()","metadata":{"papermill":{"duration":0.073698,"end_time":"2024-01-14T22:55:48.445914","exception":false,"start_time":"2024-01-14T22:55:48.372216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:08:01.13827Z","iopub.execute_input":"2024-04-07T23:08:01.138807Z","iopub.status.idle":"2024-04-07T23:08:01.17301Z","shell.execute_reply.started":"2024-04-07T23:08:01.138774Z","shell.execute_reply":"2024-04-07T23:08:01.172079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\nfiles2 = os.listdir(PATH2)\nprint(f'There are {len(files2)} test spectrogram parquets')\n    \nspectrograms2 = {}\nfor i,f in enumerate(files2):\n    if i%100==0: print(i,', ',end='')\n    tmp = pd.read_parquet(f'{PATH2}{f}')\n    name = int(f.split('.')[0])\n    spectrograms2[name] = tmp.iloc[:,1:].values\n    \n# RENAME FOR DATALOADER\ntest = test.rename({'spectrogram_id':'spec_id'},axis=1)","metadata":{"papermill":{"duration":0.257975,"end_time":"2024-01-14T22:55:48.757931","exception":false,"start_time":"2024-01-14T22:55:48.499956","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:08:01.174187Z","iopub.execute_input":"2024-04-07T23:08:01.174538Z","iopub.status.idle":"2024-04-07T23:08:01.537961Z","shell.execute_reply.started":"2024-04-07T23:08:01.174506Z","shell.execute_reply":"2024-04-07T23:08:01.537174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pywt, librosa\n\nUSE_WAVELET = None \n\nNAMES = ['LL','LP','RP','RR']\n\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\n\n# DENOISE FUNCTION\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise(x, wavelet='haar', level=1):    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n    \n    return ret\n\ndef spectrogram_from_eeg(parquet_path, display=False):\n    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    eeg = pd.read_parquet(parquet_path)\n    middle = (len(eeg)-10_000)//2\n    eeg = eeg.iloc[middle:middle+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((128,256,4),dtype='float32')\n    \n    if display: plt.figure(figsize=(10,7))\n    signals = []\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n        \n            # COMPUTE PAIR DIFFERENCES\n            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n\n            # FILL NANS\n            m = np.nanmean(x)\n            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n            else: x[:] = 0\n\n            # DENOISE\n            if USE_WAVELET:\n                x = denoise(x, wavelet=USE_WAVELET)\n            signals.append(x)\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256, \n                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n\n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//32)*32\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n\n            # STANDARDIZE TO -1 TO 1\n            mel_spec_db = (mel_spec_db+40)/40 \n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n        \n        if display:\n            plt.subplot(2,2,k+1)\n            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n            \n    if display: \n        plt.show()\n        plt.figure(figsize=(10,5))\n        offset = 0\n        for k in range(4):\n            if k>0: offset -= signals[3-k].min()\n            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n            offset += signals[3-k].max()\n        plt.legend()\n        plt.title(f'EEG {eeg_id} Signals')\n        plt.show()\n        print(); print('#'*25); print()\n        \n    return img","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-07T23:08:01.539178Z","iopub.execute_input":"2024-04-07T23:08:01.539584Z","iopub.status.idle":"2024-04-07T23:08:01.564871Z","shell.execute_reply.started":"2024-04-07T23:08:01.539547Z","shell.execute_reply":"2024-04-07T23:08:01.564075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL EEG SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nall_eegs2 = {}\n\nprint('Converting Test EEG to Spectrograms...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs2[eeg_id] = img","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:01.566063Z","iopub.execute_input":"2024-04-07T23:08:01.566414Z","iopub.status.idle":"2024-04-07T23:08:13.852298Z","shell.execute_reply.started":"2024-04-07T23:08:01.566378Z","shell.execute_reply":"2024-04-07T23:08:13.851361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER EFFICIENTNET ON TEST\npreds = []\nmodelb0 = build_modelb0()\nmodelb1 = build_modelb1()\nmodelb2 = build_modelb2()\nmodelb3 = build_modelb3()\n\ntest_gen = DataGenerator(test, shuffle=False, batch_size=128, mode='test',\n                         specs = spectrograms2, eeg_specs = all_eegs2)\n\nfor i in range(5):\n    print(f'Fold {i+1}')\n    modelb0.load_weights(f'{LOAD_MODELS_FROMb0}EffNet_v{VER}_f{i}.h5')\n    modelb1.load_weights(f'{LOAD_MODELS_FROMb1}EffNet_v{VER}_f{i}.h5')\n    modelb2.load_weights(f'{LOAD_MODELS_FROMb2}EffNet_v{VER}_f{i}.h5')\n    modelb3.load_weights(f'{LOAD_MODELS_FROMb3}EffNet_v{VER}_f{i}.h5')\n\n        \n    pred = (modelb0.predict(test_gen, verbose=1)+modelb1.predict(test_gen, verbose=1)+modelb2.predict(test_gen, verbose=1)+modelb3.predict(test_gen, verbose=1))/4\n#     pred = modelb0.predict(test_gen, verbose=1)\n    preds.append(pred)\npred1 = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred1.shape)","metadata":{"papermill":{"duration":9.827745,"end_time":"2024-01-14T22:55:58.637732","exception":false,"start_time":"2024-01-14T22:55:48.809987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:08:13.853662Z","iopub.execute_input":"2024-04-07T23:08:13.854342Z","iopub.status.idle":"2024-04-07T23:08:58.60924Z","shell.execute_reply.started":"2024-04-07T23:08:13.854304Z","shell.execute_reply":"2024-04-07T23:08:58.608497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:58.610493Z","iopub.execute_input":"2024-04-07T23:08:58.610805Z","iopub.status.idle":"2024-04-07T23:08:58.617046Z","shell.execute_reply.started":"2024-04-07T23:08:58.610778Z","shell.execute_reply":"2024-04-07T23:08:58.616071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:58.618147Z","iopub.execute_input":"2024-04-07T23:08:58.618435Z","iopub.status.idle":"2024-04-07T23:08:58.629721Z","shell.execute_reply.started":"2024-04-07T23:08:58.618399Z","shell.execute_reply":"2024-04-07T23:08:58.628703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CatBoost**","metadata":{}},{"cell_type":"code","source":"import gc\ndel files2,spectrograms2,tmp,name,test,all_eegs2,img,EEG_IDS2,modelb0,test_gen,pred,preds,modelb1,modelb2,modelb3\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:58.630956Z","iopub.execute_input":"2024-04-07T23:08:58.631586Z","iopub.status.idle":"2024-04-07T23:08:59.134388Z","shell.execute_reply.started":"2024-04-07T23:08:58.631548Z","shell.execute_reply":"2024-04-07T23:08:59.133463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:59.136416Z","iopub.execute_input":"2024-04-07T23:08:59.136809Z","iopub.status.idle":"2024-04-07T23:08:59.149794Z","shell.execute_reply.started":"2024-04-07T23:08:59.136773Z","shell.execute_reply":"2024-04-07T23:08:59.148923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE ALL EEG SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nDISPLAY = 0\nEEG_IDS2 = test.eeg_id.unique()\nall_eegs2 = {}\n\nprint('Converting Test EEG to Spectrograms...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs2[eeg_id] = img","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:59.155337Z","iopub.execute_input":"2024-04-07T23:08:59.155635Z","iopub.status.idle":"2024-04-07T23:08:59.383122Z","shell.execute_reply.started":"2024-04-07T23:08:59.155611Z","shell.execute_reply":"2024-04-07T23:08:59.381749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPEC_COLS = pd.read_parquet(f'/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/1000086677.parquet').columns[1:]\nFEATURES = [f'{c}_mean_10m' for c in SPEC_COLS]\nFEATURES += [f'{c}_min_10m' for c in SPEC_COLS]\nFEATURES += [f'{c}_mean_20s' for c in SPEC_COLS]\nFEATURES += [f'{c}_min_20s' for c in SPEC_COLS]\nFEATURES += [f'eeg_mean_f{x}_10s' for x in range(512)]\nFEATURES += [f'eeg_min_f{x}_10s' for x in range(512)]\nFEATURES += [f'eeg_max_f{x}_10s' for x in range(512)]\nFEATURES += [f'eeg_std_f{x}_10s' for x in range(512)]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:59.384995Z","iopub.execute_input":"2024-04-07T23:08:59.385566Z","iopub.status.idle":"2024-04-07T23:08:59.506978Z","shell.execute_reply.started":"2024-04-07T23:08:59.385516Z","shell.execute_reply":"2024-04-07T23:08:59.505648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FEATURE ENGINEER TEST\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\ndata = np.zeros((len(test),len(FEATURES)))\nimport warnings\nwarnings.filterwarnings('ignore')    \nfor k in range(len(test)):\n    row = test.iloc[k]\n    s = int( row.spectrogram_id )\n    spec = pd.read_parquet(f'{PATH2}{s}.parquet')\n    \n    # 10 MINUTE WINDOW FEATURES\n    x = np.nanmean( spec.iloc[:,1:].values, axis=0)\n    data[k,:400] = x\n    x = np.nanmin( spec.iloc[:,1:].values, axis=0)\n    data[k,400:800] = x\n\n    # 20 SECOND WINDOW FEATURES\n    x = np.nanmean( spec.iloc[145:155,1:].values, axis=0)\n    data[k,800:1200] = x\n    x = np.nanmin( spec.iloc[145:155,1:].values, axis=0)\n    data[k,1200:1600] = x\n    \n    # RESHAPE EEG SPECTROGRAMS 128x256x4 => 512x256\n    eeg_spec = np.zeros((512,256),dtype='float32')\n    xx = all_eegs2[row.eeg_id]\n    for j in range(4): eeg_spec[128*j:128*(j+1),] = xx[:,:,j]\n\n    # 10 SECOND WINDOW FROM EEG SPECTROGRAMS \n    x = np.nanmean(eeg_spec.T[100:-100,:],axis=0)\n    data[k,1600:2112] = x\n    x = np.nanmin(eeg_spec.T[100:-100,:],axis=0)\n    data[k,2112:2624] = x\n    x = np.nanmax(eeg_spec.T[100:-100,:],axis=0)\n    data[k,2624:3136] = x\n    x = np.nanstd(eeg_spec.T[100:-100,:],axis=0)\n    data[k,3136:3648] = x\n\ntest[FEATURES] = data\nprint('New test shape',test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:08:59.513228Z","iopub.execute_input":"2024-04-07T23:08:59.513823Z","iopub.status.idle":"2024-04-07T23:09:02.789669Z","shell.execute_reply.started":"2024-04-07T23:08:59.513784Z","shell.execute_reply":"2024-04-07T23:09:02.788762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost as cat\nfrom catboost import CatBoostClassifier, Pool\nprint('CatBoost version',cat.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:02.791005Z","iopub.execute_input":"2024-04-07T23:09:02.791283Z","iopub.status.idle":"2024-04-07T23:09:03.635532Z","shell.execute_reply.started":"2024-04-07T23:09:02.791257Z","shell.execute_reply":"2024-04-07T23:09:03.634497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER CATBOOST ON TEST\npreds = []\n\nfor i in range(5):\n    print(i,', ',end='')\n    model = CatBoostClassifier(task_type='GPU')\n    model.load_model(f'/kaggle/input/catboost-two-step/CAT_v3_f{i}.cat')\n    \n    test_pool = Pool(\n        data = test[FEATURES]\n    )\n    \n    pred = model.predict_proba(test_pool)\n    preds.append(pred)\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:03.636687Z","iopub.execute_input":"2024-04-07T23:09:03.636971Z","iopub.status.idle":"2024-04-07T23:09:06.012358Z","shell.execute_reply.started":"2024-04-07T23:09:03.636947Z","shell.execute_reply":"2024-04-07T23:09:06.011389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2=(pred/np.sum(pred,axis=1).reshape(-1,1).copy())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.013595Z","iopub.execute_input":"2024-04-07T23:09:06.013949Z","iopub.status.idle":"2024-04-07T23:09:06.019389Z","shell.execute_reply.started":"2024-04-07T23:09:06.013916Z","shell.execute_reply":"2024-04-07T23:09:06.01825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.020373Z","iopub.execute_input":"2024-04-07T23:09:06.020723Z","iopub.status.idle":"2024-04-07T23:09:06.044158Z","shell.execute_reply.started":"2024-04-07T23:09:06.020698Z","shell.execute_reply":"2024-04-07T23:09:06.043157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.045402Z","iopub.execute_input":"2024-04-07T23:09:06.04576Z","iopub.status.idle":"2024-04-07T23:09:06.057853Z","shell.execute_reply.started":"2024-04-07T23:09:06.045728Z","shell.execute_reply":"2024-04-07T23:09:06.056956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wave Net","metadata":{}},{"cell_type":"code","source":"del EEG_IDS2,all_eegs2,img,FEATURES,data,spec,x,eeg_spec,test,model,test_pool\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.058939Z","iopub.execute_input":"2024-04-07T23:09:06.059229Z","iopub.status.idle":"2024-04-07T23:09:06.335645Z","shell.execute_reply.started":"2024-04-07T23:09:06.059203Z","shell.execute_reply":"2024-04-07T23:09:06.334678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('We will use the following subset of raw EEG features:')\nFEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\nFEAT2IDX = {x:y for x,y in zip(FEATS,range(len(FEATS)))}\nprint( list(FEATS) )","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.337128Z","iopub.execute_input":"2024-04-07T23:09:06.337535Z","iopub.status.idle":"2024-04-07T23:09:06.346377Z","shell.execute_reply.started":"2024-04-07T23:09:06.337492Z","shell.execute_reply":"2024-04-07T23:09:06.345491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eeg_from_parquet(parquet_path, display=False):\n    \n    # EXTRACT MIDDLE 50 SECONDS\n    eeg = pd.read_parquet(parquet_path, columns=FEATS)\n    rows = len(eeg)\n    offset = (rows-10_000)//2\n    eeg = eeg.iloc[offset:offset+10_000]\n    \n    if display: \n        plt.figure(figsize=(10,5))\n        offset = 0\n    \n    # CONVERT TO NUMPY\n    data = np.zeros((10_000,len(FEATS)))\n    for j,col in enumerate(FEATS):\n        \n        # FILL NAN\n        x = eeg[col].values.astype('float32')\n        m = np.nanmean(x)\n        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n        else: x[:] = 0\n            \n        data[:,j] = x\n        \n        if display: \n            if j!=0: offset += x.max()\n            plt.plot(range(10_000),x-offset,label=col)\n            offset -= x.min()\n            \n    if display:\n        plt.legend()\n        name = parquet_path.split('/')[-1]\n        name = name.split('.')[0]\n        plt.title(f'EEG {name}',size=16)\n        plt.show()\n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.347624Z","iopub.execute_input":"2024-04-07T23:09:06.349583Z","iopub.status.idle":"2024-04-07T23:09:06.359166Z","shell.execute_reply.started":"2024-04-07T23:09:06.349557Z","shell.execute_reply":"2024-04-07T23:09:06.358451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.signal import butter, lfilter\n\ndef butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.360243Z","iopub.execute_input":"2024-04-07T23:09:06.360572Z","iopub.status.idle":"2024-04-07T23:09:06.370467Z","shell.execute_reply.started":"2024-04-07T23:09:06.360536Z","shell.execute_reply":"2024-04-07T23:09:06.369588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, data, batch_size=16, shuffle=False, eegs=None, mode='train',\n                 downsample=5): \n\n        self.data = data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.eegs = eegs\n        self.mode = mode\n        self.downsample = downsample\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        return X[:,::self.downsample,:], y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange( len(self.data) )\n        if self.shuffle: np.random.shuffle(self.indexes)\n                        \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n    \n        X = np.zeros((len(indexes),10_000,8),dtype='float32')\n        y = np.zeros((len(indexes),6),dtype='float32')\n        \n        sample = np.zeros((10_000,X.shape[-1]))\n        sample1 = np.zeros((10_000,X.shape[-1]))\n        for j,i in enumerate(indexes):\n            row = self.data.iloc[i]      \n            data = self.eegs[row.eeg_id]\n            \n            # FEATURE ENGINEER\n            sample[:,0] = data[:,FEAT2IDX['Fp1']] - data[:,FEAT2IDX['T3']]\n            sample[:,1] = data[:,FEAT2IDX['T3']] - data[:,FEAT2IDX['O1']]\n            \n            sample[:,2] = data[:,FEAT2IDX['Fp1']] - data[:,FEAT2IDX['C3']]\n            sample[:,3] = data[:,FEAT2IDX['C3']] - data[:,FEAT2IDX['O1']]\n            \n            sample[:,4] = data[:,FEAT2IDX['Fp2']] - data[:,FEAT2IDX['C4']]\n            sample[:,5] = data[:,FEAT2IDX['C4']] - data[:,FEAT2IDX['O2']]\n            \n            sample[:,6] = data[:,FEAT2IDX['Fp2']] - data[:,FEAT2IDX['T4']]\n            sample[:,7] = data[:,FEAT2IDX['T4']] - data[:,FEAT2IDX['O2']]\n            \n            # STANDARDIZE\n            sample = np.clip(sample,-1024,1024)\n            sample = np.nan_to_num(sample, nan=0) / 32.0\n            \n            \n            # BUTTER LOW-PASS FILTER\n            sample = butter_lowpass_filter(sample)\n            \n            sample1[:,0] = sample[:,6]\n            sample1[:,1] = sample[:,7]\n            sample1[:,2] = sample[:,4]\n            sample1[:,3] = sample[:,5]\n            sample1[:,4] = sample[:,2]\n            sample1[:,5] = sample[:,3]\n            sample1[:,6] = sample[:,0]\n            sample1[:,7] = sample[:,1]\n            X[j,] = sample1\n                \n            if self.mode!='test':\n                y[j] = row[TARGETS]\n            \n        return X,y","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.371338Z","iopub.execute_input":"2024-04-07T23:09:06.371643Z","iopub.status.idle":"2024-04-07T23:09:06.392335Z","shell.execute_reply.started":"2024-04-07T23:09:06.371612Z","shell.execute_reply":"2024-04-07T23:09:06.391614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\nimport tensorflow as tf\nprint('TensorFlow version =',tf.__version__)\n\n# USE MULTIPLE GPUS\ngpus = tf.config.list_physical_devices('GPU')\nif len(gpus)<=1: \n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    print(f'Using {len(gpus)} GPU')\nelse: \n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} GPUs')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.393327Z","iopub.execute_input":"2024-04-07T23:09:06.393614Z","iopub.status.idle":"2024-04-07T23:09:06.410984Z","shell.execute_reply.started":"2024-04-07T23:09:06.39359Z","shell.execute_reply":"2024-04-07T23:09:06.4102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MIXED PRECISION\nMIX = True\nif MIX:\n    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n    print('Mixed precision enabled')\nelse:\n    print('Using full precision')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.412172Z","iopub.execute_input":"2024-04-07T23:09:06.412544Z","iopub.status.idle":"2024-04-07T23:09:06.420108Z","shell.execute_reply.started":"2024-04-07T23:09:06.412503Z","shell.execute_reply":"2024-04-07T23:09:06.419248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate\n\ndef wave_block(x, filters, kernel_size, n):\n    dilation_rates = [2**i for i in range(n)]\n    x = Conv1D(filters = filters,\n               kernel_size = 1,\n               padding = 'same')(x)\n    res_x = x\n    for dilation_rate in dilation_rates:\n        tanh_out = Conv1D(filters = filters,\n                          kernel_size = kernel_size,\n                          padding = 'same', \n                          activation = 'tanh', \n                          dilation_rate = dilation_rate)(x)\n        sigm_out = Conv1D(filters = filters,\n                          kernel_size = kernel_size,\n                          padding = 'same',\n                          activation = 'sigmoid', \n                          dilation_rate = dilation_rate)(x)\n        x = Multiply()([tanh_out, sigm_out])\n        x = Conv1D(filters = filters,\n                   kernel_size = 1,\n                   padding = 'same')(x)\n        res_x = Add()([res_x, x])\n    return res_x","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.421296Z","iopub.execute_input":"2024-04-07T23:09:06.421693Z","iopub.status.idle":"2024-04-07T23:09:06.43358Z","shell.execute_reply.started":"2024-04-07T23:09:06.421657Z","shell.execute_reply":"2024-04-07T23:09:06.432703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n        \n    # INPUT \n    inp = tf.keras.Input(shape=(2_000,8))\n    \n    ############\n    # FEATURE EXTRACTION SUB MODEL\n    inp2 = tf.keras.Input(shape=(2_000,1))\n    x = wave_block(inp2, 8, 4, 6)\n    x = wave_block(x, 16, 4, 6)\n    x = wave_block(x, 32, 4, 6)\n    x = wave_block(x, 64, 4, 6)\n    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n    ###########\n    \n    # LEFT TEMPORAL CHAIN\n    x1 = model2(inp[:,:,0:1])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,1:2])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z1 = tf.keras.layers.Average()([x1,x2])\n    \n    # LEFT PARASAGITTAL CHAIN\n    x1 = model2(inp[:,:,2:3])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,3:4])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z2 = tf.keras.layers.Average()([x1,x2])\n    \n    # RIGHT PARASAGITTAL CHAIN\n    x1 = model2(inp[:,:,4:5])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,5:6])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z3 = tf.keras.layers.Average()([x1,x2])\n    \n    # RIGHT TEMPORAL CHAIN\n    x1 = model2(inp[:,:,6:7])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,7:8])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z4 = tf.keras.layers.Average()([x1,x2])\n    \n    # COMBINE CHAINS\n    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n    y = tf.keras.layers.Dense(64, activation='relu')(y)\n    y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n    \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=y)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n    model.compile(loss=loss, optimizer = opt)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.434578Z","iopub.execute_input":"2024-04-07T23:09:06.434849Z","iopub.status.idle":"2024-04-07T23:09:06.45234Z","shell.execute_reply.started":"2024-04-07T23:09:06.434826Z","shell.execute_reply":"2024-04-07T23:09:06.451476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape:',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.453584Z","iopub.execute_input":"2024-04-07T23:09:06.453953Z","iopub.status.idle":"2024-04-07T23:09:06.477267Z","shell.execute_reply.started":"2024-04-07T23:09:06.45392Z","shell.execute_reply":"2024-04-07T23:09:06.476471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_eegs2 = {}\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n\nprint('Processing Test EEG parquets...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n    data = eeg_from_parquet(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs2[eeg_id] = data","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:06.478395Z","iopub.execute_input":"2024-04-07T23:09:06.478691Z","iopub.status.idle":"2024-04-07T23:09:07.228114Z","shell.execute_reply.started":"2024-04-07T23:09:06.478666Z","shell.execute_reply":"2024-04-07T23:09:07.22718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER MLP ON TEST\npreds = []\nmodel = build_model()\nFOLDS_TO_TRAIN=5\ntest_gen = DataGenerator(test, shuffle=False, batch_size=64, eegs=all_eegs2, mode='test')\n\nprint('Inferring test... ',end='')\nfor i in range(FOLDS_TO_TRAIN):\n    print(f'fold {i+1}, ',end='')\n    model.load_weights(f'/kaggle/input/2-step-wave-net/WaveNet_Model/WaveNet_fold{i}.h5')\n    pred = model.predict(test_gen, verbose=0)\n    preds.append(pred)\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:07.229296Z","iopub.execute_input":"2024-04-07T23:09:07.2296Z","iopub.status.idle":"2024-04-07T23:09:39.622769Z","shell.execute_reply.started":"2024-04-07T23:09:07.229574Z","shell.execute_reply":"2024-04-07T23:09:39.621846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred3=(pred/np.sum(pred,axis=1).reshape(-1,1).copy())\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:39.623908Z","iopub.execute_input":"2024-04-07T23:09:39.624207Z","iopub.status.idle":"2024-04-07T23:09:39.629159Z","shell.execute_reply.started":"2024-04-07T23:09:39.62418Z","shell.execute_reply":"2024-04-07T23:09:39.627929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred3","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:39.630515Z","iopub.execute_input":"2024-04-07T23:09:39.630874Z","iopub.status.idle":"2024-04-07T23:09:39.645441Z","shell.execute_reply.started":"2024-04-07T23:09:39.630839Z","shell.execute_reply":"2024-04-07T23:09:39.644638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred3.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:09:39.646602Z","iopub.execute_input":"2024-04-07T23:09:39.646913Z","iopub.status.idle":"2024-04-07T23:09:39.65754Z","shell.execute_reply.started":"2024-04-07T23:09:39.646876Z","shell.execute_reply":"2024-04-07T23:09:39.656608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# All together","metadata":{}},{"cell_type":"code","source":"pred=((0.80*pred1)+(0.05*pred2)+(0.15*pred3))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T23:11:21.958968Z","iopub.execute_input":"2024-04-07T23:11:21.959756Z","iopub.status.idle":"2024-04-07T23:11:21.964324Z","shell.execute_reply.started":"2024-04-07T23:11:21.959721Z","shell.execute_reply":"2024-04-07T23:11:21.963388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub[TARGETS] = pred\nsub.to_csv('submission.csv',index=False)\nprint('Submissionn shape',sub.shape)\nsub.head()","metadata":{"papermill":{"duration":0.071388,"end_time":"2024-01-14T22:55:58.760368","exception":false,"start_time":"2024-01-14T22:55:58.68898","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:11:22.284988Z","iopub.execute_input":"2024-04-07T23:11:22.285301Z","iopub.status.idle":"2024-04-07T23:11:22.303395Z","shell.execute_reply.started":"2024-04-07T23:11:22.285274Z","shell.execute_reply":"2024-04-07T23:11:22.30248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nsub.iloc[:,-6:].sum(axis=1)","metadata":{"papermill":{"duration":0.062742,"end_time":"2024-01-14T22:55:58.873394","exception":false,"start_time":"2024-01-14T22:55:58.810652","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-07T23:11:38.600552Z","iopub.execute_input":"2024-04-07T23:11:38.60092Z","iopub.status.idle":"2024-04-07T23:11:38.610189Z","shell.execute_reply.started":"2024-04-07T23:11:38.60089Z","shell.execute_reply":"2024-04-07T23:11:38.609223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}